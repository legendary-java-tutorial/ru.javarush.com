BigData: HBase
<p>----------------------------------------</p>
Кто и зачем придумал HBase. 
Модель данных. 
Поддерживаемые операции. 
Архитектура. 
Способы работы с HBase. 
Некоторые особенности работы с HBase. 
Альтернативы.
<p>----------------------------------------</p>
<h2>6.1 Кто и зачем придумал HBase</h2>

<p>В этой лекции мы поговорим про такой замечательный инструмент как Hbase, который в последнее время завоевал большую популярность: например, Facebook использует его в качестве основы своей системы обмена сообщений, а это уже говорит о многом. </p>

<p>В лекции будет рассказано про концепцию Big Table и её свободную реализацию, особенности работы и отличие как от классических реляционных баз данных (таких как MySQL и Oracle), так и key-value хранилищ, таких как Redis, Aerospike и memcached. 
Как обычно — начнём с истории вопроса. Как и многие другие проекты из области BigData, Hbase зародилась из концепции, которая была разработана в компании Google. Принципы лежащие в основе Hbase, были описаны в статье <a href="http://static.googleusercontent.com/media/research.google.com/ru/archive/bigtable-osdi06.pdf" target="_blank">Bigtable: A Distributed Storage System for Structured Data</a>. </p>

<p>Как мы рассматривали в прошлых лекциях — обычные файлы довольно неплохо подходят для пакетной обработки данных, с использованием парадигмы MapReduce. 
С другой стороны, информацию хранящуюся в файлах довольно неудобно обновлять; Файлы также лишены возможности произвольного доступа. Для быстрой и удобной работы с произвольным доступом есть класс nosql-систем типа key-value storage, таких как Aerospike, Redis, Couchbase, Memcached. Однако в обычно в этих системах очень неудобна пакетная обработка данных. Hbase представляет из себя попытку объединения удобства пакетной обработки и удобства обновления и произвольного доступа. </p>

<img data-max-width="512" data-id="03325dc1-1ff2-4679-bbae-54fe916d9429" src="https://cdn.javarush.com/images/article/03325dc1-1ff2-4679-bbae-54fe916d9429/original.png" alt="">
 
<h2>6.2 Модель данных </h2>

<p>HBase — это распределенная, колоночно-ориентированная, мультиверсионная база типа «ключ-значение». </p>

<ul>
<li>Данные организованы в таблицы, проиндексированные первичным ключом, который в Hbase называется RowKey. </li>
<li>Для каждого RowKey ключа может храниться неограниченны набор атрибутов (или колонок). </li>
<li>Колонки организованны в группы колонок, называемые Column Family. Как правило в одну Column Family объединяют колонки, для которых одинаковы паттерн использования и хранения.</li>
<li>Для каждого аттрибута может храниться несколько различных версий. Разные версии имеют разный timestamp. </li>
</ul>

<p>Записи физически хранятся в отсортированном по RowKey порядке. При этом данные, соответствующие разным Column Family хранятся отдельно, что позволяет при необходимости читать данные только из нужного семейства колонок. </p>

<p>При удалении определённого атрибута физически он сразу не удаляется, а лишь маркируется специальным флажком tombstone. Физическое удаление данных произойдет позже, при выполнении операции Major Compaction. </p>

<p>Атрибуты, принадлежащие одной группе колонок и соответствующие одному ключу физически хранятся как отсортированный список. Любой атрибут может отсутствовать или присутствовать для каждого ключа, при этом если атрибут отсутствует — это не вызывает накладных расходов на хранение пустых значений. </p>

<p>Список и названия групп колонок фиксирован и имеет четкую схему. На уровне группы колонок задаются такие параметры как time to live (TTL) и максимальное количество хранимых версий. Если разница между timestamp для определенно версии и текущим временем больше TTL — запись помечается к удалению. Если количество версий для определённого атрибута превысило максимальное количество версий — запись также помечается к удалению. </p>

<img data-max-width="512" data-id="38a31201-f909-4a45-9792-a5d72225f060" src="https://cdn.javarush.com/images/article/38a31201-f909-4a45-9792-a5d72225f060/original.png" alt="">
 
<p>Модель данных Hbase можно запомнить, как соответствие ключ значение: </p>
 
<pre><code>&lt;table, RowKey, Column Family, Column, timestamp> -> Value
</code></pre>  
 
<h2>6.3 Поддерживаемые операции </h2>

<p>Список поддерживаемых операций в hbase весьма прост. Поддерживаются 4 основные операции: </p>

<ul>
<li><strong>Put</strong>: добавить новую запись в hbase. Timestamp этой записи может быть задан руками, в противном случае он будет установлен автоматически как текущее время. </li>
<li><strong>Get</strong>: получить данные по определенному RowKey. Можно указать Column Family, из которой будем брать данные и количество версий которые хотим прочитать. </li>
<li><strong>Scan</strong>: читать записи по очереди. Можно указать запись с которой начинаем читать, запись до которой читать, количество записей которые необходимо считать, Column Family из которой будет производиться чтение и максимальное количество версий для каждой записи. </li>
<li><strong>Delete</strong>: пометить определенную версию к удалению. Физического удаления при этом не произойдет, оно будет отложено до следующего Major Compaction (см. ниже). </li>
</ul>
 
<h2>6.4 Архитектура </h2>

<p>HBase является распределенной базой данных, которая может работать на десятках и сотнях физических серверов, обеспечивая бесперебойную работу даже при выходе из строя некоторых из них. Поэтому архитектура HBase довольна сложна по сравнению с классическими реляционными базами данных. </p>

<img data-max-width="1024" data-id="5bae086c-b213-47db-be33-a23d854a1543" src="https://cdn.javarush.com/images/article/5bae086c-b213-47db-be33-a23d854a1543/original.png" alt="">
 
<p>HBase для своей работы использует два основных процесса: </p>

<p><strong>1. Region Server</strong> — обслуживает один или несколько регионов. Регион — это диапазон записей, соответствующих определенному диапазону подряд идущих RowKey. Каждый регион содержит: </p>

<ul>
<li><strong>Persistent Storage</strong> — основное хранилище данных в HBase. Данные физически хранятся на HDFS, в специальном формате HFile. Данные в HFile хранятся в отсортированном по RowKey порядке. Одной паре (регион, column family) соответствует как минимум один HFIle. </li>
<li><strong>MemStore</strong> — буфер на запись. Так как данные хранятся в HFile d отсортированном порядке — обновлять HFile на каждую запись довольно дорого. Вместо этого данные при записи попадают в специальную область памяти MemStore, где накапливаются некоторое время. При наполнении MemStore до некоторого критического значения данные записываются в новый HFile. </li>
<li><strong>BlockCache</strong> — кэш на чтение. Позволяет существенно экономить время на данных которые читаются часто. </li>
<li><strong>Write Ahead Log (WAL)</strong>. Так как данные при записи попадают в memstore, существует некоторый риск потери данных из-за сбоя. Для того чтобы этого не произошло все операции перед собственно осуществление манипуляций попадают в специальный лог-файл. Это позволяет восстановить данные после любого сбоя. </li>
</ul>
 
<p><strong>2. Master Server</strong> — главный сервер в кластере HBase. Master управляет распределением регионов по Region Server’ам, ведет реестр регионов, управляет запусками регулярных задач и делает другую полезную работу. </p>

<p>Для координации действий между сервисами HBase использует Apache ZooKeeper, специальный сервис, предназначенный для управления конфигурациями и синхронизацией сервисов. </p>

<p>При увеличении количества данных в регионе и достижении им определенного размера Hbase запускает split, операцию разбивающую регион на 2. Для того чтобы избежать постоянных делений регионов — можно заранее задать границы регионов и увеличить их максимальный размер. </p>

<p>Так как данные по одному региону могут храниться в нескольких HFile, для ускорения работы Hbase периодически их сливает воедино. Эта операция в Hbase называется compaction. Compaction’ы бывают двух видов: </p>

<ul>
<li><strong>Minor Compaction</strong>. Запускается автоматически, выполняется в фоновом режиме. Имеет низкий приоритет по сравнению с другими операциями Hbase. </li>
<li><strong>Major Compaction</strong>. Запускается руками или по наступлению срабатыванию определенных триггеров (например по таймеру). Имеет высокий приоритет и может существенно замедлить работу кластера. Major Compaction’ы лучше делать во время когда нагрузка на кластер небольшая. Во время Major Compaction также происходит физическое удаление данных, ране помеченных меткой tombstone. </li>
</ul>

<h2>6.5 Способы работы с HBase </h2>

<h4>HBase Shell </h4>

Самый простой способ начать работу с Hbase — воспользоваться утилитой hbase shell. Она доступна сразу после установки hbase на любой ноде кластера hbase. 

<img data-max-width="512" data-id="e1bc7480-e6e9-4358-9632-9349e4bd5a02" src="https://cdn.javarush.com/images/article/e1bc7480-e6e9-4358-9632-9349e4bd5a02/original.png" alt="">
 
<p>Hbase shell представляет из себя jruby-консоль c встроенной поддержкой всех основных операций по работе с Hbase. Ниже приведён пример создания таблицы users с двумя column family, выполнения некоторых манипуляций с ней и удаление таблицы в конце на языке hbase shell: </p>

<pre><code>create 'users', {NAME => 'user_profile', VERSIONS => 5}, {NAME => 'user_posts', VERSIONS => 1231231231} 
put 'users', 'id1', 'user_profile:name', 'alexander' 
put 'users', 'id1', 'user_profile:second_name', 'alexander' 
get 'users', 'id1' 
put 'users', 'id1', 'user_profile:second_name', 'kuznetsov' 
get 'users', 'id1' 
get 'users', 'id1', {COLUMN => 'user_profile:second_name', VERSIONS => 5} 
put 'users', 'id2', 'user_profile:name', 'vasiliy' 
put 'users', 'id2', 'user_profile:second_name', 'ivanov' 
scan 'users', {COLUMN => 'user_profile:second_name', VERSIONS => 5} 
delete 'users', 'id1', 'user_profile:second_name' 
get 'users', 'id1' 
disable 'users' 
drop 'users'
</code></pre> 
 
<h4>Native API </h4>

<p>Как и большинство других hadoop-related проектов hbase реализован на языке java, поэтому и нативный api доступен на языке Java. Native API довольно неплохо задокументирован на официальном сайте. Вот пример использования Hbase API взятый оттуда же: </p>

<pre class='language-java line-numbers'><code>
import java.io.IOException; 
 
import org.apache.hadoop.hbase.*; 
import org.apache.hadoop.hbase.client.*; 
import org.apache.hadoop.hbase.util.Bytes; 
 
public class MyLittleHBaseClient { 
  public static void main(String[] args) throws IOException { 
	Configuration config = HBaseConfiguration.create(); 
	Connection connection = ConnectionFactory.createConnection(config); 
	try { 
  	Table table = connection.getTable(TableName.valueOf("myLittleHBaseTable")); 
  	try { 
    	Put p = new Put(Bytes.toBytes("myLittleRow")); 
    	p.add(Bytes.toBytes("myLittleFamily"), Bytes.toBytes("someQualifier"), 
    	Bytes.toBytes("Some Value")); 
    	table.put(p); 
 
    	Get g = new Get(Bytes.toBytes("myLittleRow")); 
    	Result r = table.get(g); 
    	byte [] value = r.getValue(Bytes.toBytes("myLittleFamily"), 
      	Bytes.toBytes("someQualifier")); 
 
    	String valueStr = Bytes.toString(value); 
    	System.out.println("GET: " + valueStr); 
 
    	Scan s = new Scan(); 
    	s.addColumn(Bytes.toBytes("myLittleFamily"), Bytes.toBytes("someQualifier")); 
    	ResultScanner scanner = table.getScanner(s); 
    	try { 
       	for (Result rr = scanner.next(); rr != null; rr = scanner.next()) { 
         	System.out.println("Found row: " + rr); 
       	} 
     	} finally { 
       	scanner.close(); 
     	} 
   	} finally { 
     	if (table != null) table.close(); 
   	} 
 	} finally { 
   	connection.close(); 
 	} 
  } 
} 
</code></pre>
 
<h4>Thrift, REST и поддержка других языков программирования</h4>

<p>Для работы из других языков программирования Hbase предоставляет Thrift API и Rest API. На базе них построены клиенты для всех основных языков программирования: python, PHP, Java Script и тд.</p>
 
<h2>6.6 Некоторые особенности работы с HBase </h2>

<ol>
<li><p>Hbase «из коробки» интегрируется с MapReduce, и может быть использована в качестве входных и выходных данных с помощью специальных TableInputFormat и TableOutputFormat. </p></li>
<li><p>Очень важно правильно выбрать RowKey. RowKey должен обеспечивать хорошее равномерное распределение по регионам, в противном случае есть риск возникновения так называемых «горячих регионов» — регионов которые используются гораздо чаще остальных, что приводит к неэффективному использованию ресурсов системы. </p></li>
<li><p>Если данные заливаются не единично, а сразу большими пачками — Hbase поддерживает специальный механизм BulkLoad, который позволяет заливать данные намного быстрее чем используя единичные Put’ы. BulkLoad по сути представляет из себя двухшаговую операцию: </p>

<ul>
<li>Формирование HFile без участия put’ов при помощи специального MapReduce job’a </li>
<li>Подкладывание этих файликов напрямую в Hbase</li>
</ul></li>

<li><p>Hbase поддерживает вывод своих метрик в сервер мониторинга Ganglia. Это может быть очень полезно при администрировании Hbase для понимания сути происходящих с hbase проблем. </p></li>
</ol>

<h4>RowKey </h4>

<p>В качестве RowKey используется идентификатор пользователя, в качестве которого используется GUUID, строчка, специально генерируемая таким образом, чтобы быть уникальной во всем мире. GUUID’ы распределены равномерно, что дает хорошее распределение данных по серверам. </p>

<h4>Column Family </h4>

<p>В нашем хранилище используются две column family: </p>

<ul>
<li>Data. В этой группе колонок хранятся данные, которые теряют свою актуальность для рекламных целей, такие как факты посещения пользователем определенных URL. TTL на эту Column Family установлен в размере 2 месяца, ограничение по количеству версий — 2000. </li>
<li>LongData. В этой группе колонок хранятся данные, которые не теряют свою актуальность в течение долгого времени, такие как пол, дата рождения и другие «вечные» характеристики пользователя.</li>
</ul>

<h4>Колонки </h4>

<p>Каждый тип фактов о пользователе хранится в отдельной колонке. Например в колонке Data:_v хранятся URL, посещенные пользователем, а в колонке LongData:gender — пол пользователя. </p>

<p>В качестве timestamp хранится время регистрации этого факта. Например в колонке Data:_v — в качестве timestamp используется время захода пользователем на определенный URL. </p>

<p>Такая структура хранения пользовательских данных очень хорошо ложится на наш паттерн использования и позволяет быстро обновлять данные о пользователях, быстро доставать всю необходимую информацию о пользователях, и, используя MapReduce, быстро обрабатывать данные обо всех пользователях сразу. </p>
 
<h2>6.7 Альтернативы </h2>

<p>HBase довольно сложна в администрировании и использовании, поэтому прежде чем использовать HBase есть смысл обратить внимание на альтернативы: </p>

<ul>
<li><p><strong>Реляционные базы данных</strong>. Очень неплохая альтернатива, особенно в случае, когда данные влезают на одну машину. Также в первую очередь о реляционных базах данных стоит подумать в случае, когда важны транзакции индексы отличные от первичного. </p></li>
<li><p><strong>Key-Value хранилища</strong>. Такие хранилища как Redis и Aerospike лучше подходят, когда необходима минимизация latency и менее важна пакетная обработка данных. </p></li>
<li><p><strong>Файлы и их обработка при помощи MapReduce</strong>. Если данные только добавляются, и редко обновляются/изменяются, то лучше не использовать HBase, а просто хранить данные в файлах. Для упрощения работы с файлами можно воспользоваться такими инструментами как Hive, Pig и Impala.</p></li>
</ul>

<p>Использование HBase оправдано когда: </p>

<ul>
<li>Данных много, и они не влезают на один компьютер/сервер </li>
<li>Данные часто обновляются и удаляются </li>
<li>В данных присутствует явный «ключ» по к которому удобно привязывать все остальное </li>
<li>Нужна пакетная обработка данных </li>
<li>Нужен произвольный доступ к данным по определенным ключам</li>
</ul>