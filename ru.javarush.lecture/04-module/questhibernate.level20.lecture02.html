Big Data: MapReduce
<p>----------------------------------------</p>
История появление термина BigData. 
Принципы работы с большими данными. 
MapReduce. 
Примеры задач, эффективно решаемых при помощи MapReduce.
<p>----------------------------------------</p>
<h2>3.1 История появление термина BigData </h2>

<p>Термин Big Data появился сравнительно недавно. Google Trends <a href="https://www.google.com/trends/explore" target="_blank">показывает</a> начало активного роста употребления словосочетания начиная с 2011 года: 

<img data-max-width="512" data-id="ef092ce5-6fc8-454f-abb3-dc34b5e97468" src="https://cdn.javarush.com/images/article/ef092ce5-6fc8-454f-abb3-dc34b5e97468/original.png" alt="">
 
<p>При этом уже сейчас термин не использует только ленивый. Особенно часто не по делу термин используют маркетологи. Так что же такое Big Data на самом деле? Раз уж я решил системно изложить и осветить вопрос – необходимо определиться с понятием. </p>

<p>В своей практике я встречался с разными определениями: </p>

<ul>
<li>Big Data – это когда данных больше, чем 100Гб (500Гб, 1ТБ, кому что нравится). </li>
<li>Big Data – это такие данные, которые невозможно обрабатывать в Excel. </li>
<li>Big Data – это такие данные, которые невозможно обработать на одном компьютере. </li>
</ul>

<p>И даже такие: </p>

<ul>
<li>Вig Data – это вообще любые данные. </li>
<li>Big Data не существует, ее придумали маркетологи. </li>
</ul>

<p>Я буду придерживаться определения с wikipedia: </p>

<p><strong>Большие данные (англ. big data)</strong> — серия подходов, инструментов и методов обработки структурированных и неструктурированных данных огромных объёмов и значительного многообразия для получения воспринимаемых человеком результатов, эффективных в условиях непрерывного прироста, распределения по многочисленным узлам вычислительной сети, сформировавшихся в конце 2000-х годов, альтернативных традиционным системам управления базами данных и решениям класса Business Intelligence. </p>

<p>Таким образом под <strong>Big Data</strong> я буду понимать не какой-то конкретный объём данных и даже не сами данные, а методы их обработки, которые позволяют распредёлено обрабатывать информацию. Эти методы можно применить как к огромным массивам данных (таким как содержание всех страниц в интернете), так и к маленьким (таким как содержимое этой лекции).</p>
 
<p>Приведу несколько примеров того, что может быть источником данных, для которых необходимы методы работы с большими данными: </p>

<ul>
<li>Логи поведения пользователей в интернете </li>
<li>GPS-сигналы от автомобилей для транспортной компании </li>
<li>Данные, снимаемые с датчиков в большом адронном коллайдере </li>
<li>Оцифрованные книги в Российской Государственной Библиотеке </li>
<li>Информация о транзакциях всех клиентов банка </li>
<li>Информация обо всех покупках в крупной ритейл сети и т.д. </li>
</ul>

<p>Количество источников данных стремительно растёт, а значит технологии их обработки становятся всё более востребованными.</p>
 
<h2>3.2 Принципы работы с большими данными </h2>

<p>Исходя из определения Big Data, можно сформулировать основные принципы работы с такими данными: </p>

<p><strong>1. Горизонтальная масштабируемость.</strong> Поскольку данных может быть сколь угодно много – любая система, которая подразумевает обработку больших данных, должна быть расширяемой. В 2 раза вырос объём данных – в 2 раза увеличили количество железа в кластере и всё продолжило работать. </p>

<p><strong>2. Отказоустойчивость.</strong> Принцип горизонтальной масштабируемости подразумевает, что машин в кластере может быть много. Например, Hadoop-кластер Yahoo имеет более 42000 машин (по этой ссылке можно посмотреть размеры кластера в разных организациях). Это означает, что часть этих машин будет гарантированно выходить из строя. Методы работы с большими данными должны учитывать возможность таких сбоев и переживать их без каких-либо значимых последствий. </p>

<p><strong>3. Локальность данных.</strong> В больших распределённых системах данные распределены по большому количеству машин. Если данные физически находятся на одном сервере, а обрабатываются на другом – расходы на передачу данных могут превысить расходы на саму обработку. Поэтому одним из важнейших принципов проектирования BigData-решений является принцип локальности данных – по возможности обрабатываем данные на той же машине, на которой их храним. </p>

<p>Все современные средства работы с большими данными так или иначе следуют этим трём принципам. Для того, чтобы им следовать – необходимо придумывать какие-то методы, способы и парадигмы разработки средств разработки данных. Один из самых классических методов я разберу в сегодняшней лекции. </p>
 
<h2>3.3 MapReduce </h2>

<p><strong>MapReduce</strong> – это модель распределенной обработки данных, предложенная компанией Google для обработки больших объёмов данных на компьютерных кластерах. MapReduce неплохо иллюстрируется следующей картинкой: </p>

<img data-max-width="512" data-id="982b3d98-934f-439d-8f04-5f0994ed46c9" src="https://cdn.javarush.com/images/article/982b3d98-934f-439d-8f04-5f0994ed46c9/original.png" alt="">
 
<p>MapReduce предполагает, что данные организованы в виде некоторых записей. Обработка данных происходит в 3 стадии: </p>

<p><strong>1. Стадия Map</strong>. На этой стадии данные предобрабатываются при помощи функции map(), которую определяет пользователь. Работа этой стадии заключается в предобработке и фильтрации данных. Работа очень похожа на операцию map в функциональных языках программирования – пользовательская функция применяется к каждой входной записи. </p>

<p><strong>Функция map() примененная к одной входной записи и выдаёт множество пар ключ-значение.</strong> Множество – т. е. может выдать только одну запись, может не выдать ничего, а может выдать несколько пар ключ-значение. Что будет находиться в ключе и в значении – решать пользователю, но ключ – очень важная вещь, так как данные с одним ключом в будущем попадут в один экземпляр функции reduce. </p>

<p><strong>2. Стадия Shuffle.</strong> Проходит незаметно для пользователя. В этой стадии вывод функции map «разбирается по корзинам» – каждая корзина соответствует одному ключу вывода стадии map. В дальнейшем эти корзины послужат входом для reduce. </p>

<p><strong>3. Стадия Reduce.</strong> Каждая «корзина» со значениями, сформированная на стадии shuffle, попадает на вход функции reduce(). </p>

<p><strong>Функция reduce задаётся пользователем и вычисляет финальный результат для отдельной «корзины»</strong>. Множество всех значений, возвращённых функцией reduce(), является финальным результатом MapReduce-задачи. </p>

<p>Несколько дополнительных фактов про MapReduce: </p>

<ol>
<li>Все запуски функции <strong>map</strong> работают независимо и могут работать параллельно, в том числе на разных машинах кластера. </li>
<li>Все запуски функции <strong>reduce</strong> работают независимо и могут работать параллельно, в том числе на разных машинах кластера. </li>
<li>Shuffle внутри себя представляет параллельную сортировку, поэтому также может работать на разных машинах кластера. <strong>Пункты 1-3 позволяют выполнить принцип горизонтальной масштабируемости</strong>. </li>
<li>Функция map, как правило, применяется на той же машине, на которой хранятся данные – это позволяет снизить передачу данных по сети (принцип локальности данных). </li>
<li>MapReduce – это всегда полное сканирование данных, никаких индексов нет. Это означает, что MapReduce плохо применим, когда ответ требуется очень быстро. </li>
</ol>

<h2>3.4 Примеры задач, эффективно решаемых при помощи MapReduce </h2>

<h4>Word Count </h4>

<p>Начнём с классической задачи – Word Count. Задача формулируется следующим образом: имеется большой корпус документов. Задача – для каждого слова, хотя бы один раз встречающегося в корпусе, посчитать суммарное количество раз, которое оно встретилось в корпусе. </p>

<h4>Решение: </h4>

<p>Раз имеем большой корпус документов – пусть один документ будет одной входной записью для MapRreduce–задачи. В MapReduce мы можем только задавать пользовательские функции, что мы и сделаем (будем использовать python-like псевдокод): </p>

<table>
<tbody>
<tr>
<td><pre><code>def map(doc): 
for word in doc: 
yield word, 1 </code></pre></td>

<td><pre><code>def reduce(word, values): 
yield word, sum(values) </code></pre></td>
 </tr>
</tbody>
</table>

<p>Функция <strong>map</strong> превращает входной документ в набор пар (слово, 1), <strong>shuffle</strong> прозрачно для нас превращает это в пары (слово, [1,1,1,1,1,1]), <strong>reduce</strong> суммирует эти единички, возвращая финальный ответ для слова. </p>

<h4>Обработка логов рекламной системы </h4>

<p>Второй пример взят из реальной практики Data-Centric Alliance. </p>

<p><strong>Задача:</strong> имеется csv-лог рекламной системы вида: </p>

<pre><code>&lt;user_id>,&lt;country>,&lt;city>,&lt;campaign_id>,&lt;creative_id>,&lt;payment>&lt;/p> 
 
11111,RU,Moscow,2,4,0.3 
22222,RU,Voronezh,2,3,0.2 
13413,UA,Kyiv,4,11,0.7 
… </code></pre>
 
<p>Необходимо рассчитать среднюю стоимость показа рекламы по городам России. </p>

<h4>Решение: </h4>

<table>
<tbody>
<tr>
<td><pre><code>def map(record): 
user_id, country, city, campaign_id, creative_id, payment = record.split(",") 
payment=float(payment) 
if country == "RU": 
yield city, payment </code></pre></td>
</tr>
<tr>
<td><pre><code>def reduce(city, payments): 
yield city, sum(payments)/len(payments) 
</code></pre></td>
</tr>
</tbody>
</table>

<p>Функция <strong>map</strong> проверяет, нужна ли нам данная запись – и если нужна, оставляет только нужную информацию (город и размер платежа). Функция <strong>reduce</strong> вычисляет финальный ответ по городу, имея список всех платежей в этом городе.</p>