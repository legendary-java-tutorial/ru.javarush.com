Машинное обучение для Java-разработчиков, часть 2
<p>----------------------------------------</p>
Напомним, целевая функция hθ, она же — функция предсказаний, является результатом процесса подготовки или тренировки. Математически сложность состоит в том, чтобы найти функцию, которая получает на вход переменную х и возвращает предсказанное значение у ...
<p>----------------------------------------</p>
<a href='https://javarush.com/groups/posts/469-mashinnoe-obuchenie-dlja-java-razrabotchikov-ch1' target='_blank'>Машинное обучение для Java-разработчиков, часть 1</a>

<div class='row justify-content-center jr-image-wrap'><div class='col-12 col-sm-10 col-md-8'><img data-id="243c544a-dd04-406b-8d81-abf900557ec6" data-max-width="710" alt="Машинное обучение для Java-разработчиков, часть 2 - 1" src="https://cdn.javarush.com/images/article/243c544a-dd04-406b-8d81-abf900557ec6/1024.jpeg"></div></div><h3>Оценка целевой функции</h3>Напомним, целевая функция <code>hθ</code>, она же — функция предсказаний, является результатом процесса подготовки или тренировки. Математически сложность состоит в том, чтобы найти функцию, которая получает на вход переменную <code>х</code> и возвращает предсказанное значение <code>у</code>. 

<div class='row justify-content-center jr-image-wrap'><div class='col-12 col-sm-10 col-md-8'><img data-max-width="149" alt="Машинное обучение для Java-разработчиков, часть 2 - 2" src="https://cdn.javarush.com/images/article/c47983fb-a5ff-4ca5-8915-d9fd54e0f1ed/original.jpeg"></div></div>

В машинном обучении функция стоимости <code>(J(θ))</code> используется для вычисления ошибки значения или «стоимости» заданной целевой функции.

<div class='row justify-content-center jr-image-wrap'><div class='col-12 col-sm-10 col-md-8'><img data-id="db420e54-8288-4a1d-b22a-a2322692eed0" data-max-width="298" alt="Машинное обучение для Java-разработчиков, часть 2 - 3" src="https://cdn.javarush.com/images/article/db420e54-8288-4a1d-b22a-a2322692eed0/1024.jpeg"></div></div>
Функция стоимости показывает, насколько точно модель соответствует тренировочным данным. Для определения стоимости целевой функции, показанной выше, необходимо рассчитать квадратичную ошибку каждого примера дома <code>(i)</code>. Ошибка – расстояние между расчетным значением <code>у</code> и настоящим значением <code>y</code> дома из примера <code>i</code>. 

<div class='row justify-content-center jr-image-wrap'><div class='col-12 col-sm-10 col-md-8'><img data-id="c3bd243a-8295-41a1-8b98-812214cae227" data-max-width="700" alt="Машинное обучение для Java-разработчиков, часть 2 - 4" src="https://cdn.javarush.com/images/article/c3bd243a-8295-41a1-8b98-812214cae227/1024.jpeg"></div></div> 
Например, реальная цена дома площадью <strong>1330 = 6,500,000 €</strong>. А отличие предсказанной цены дома обученной целевой функцией составляет <strong>7,032,478 €</strong>: разница (или ошибка) равна <strong>532,478 €</strong>. Вы также можете увидеть эту разницу на графике выше. Разница (или ошибка) показана в виде вертикальных пунктирных красных линий для каждой тренировочной пары цена – площадь.

Высчитав стоимость обученной целевой функции, нужно просуммировать квадраты ошибки для каждого дома в примере и рассчитать основное значение. Чем меньше значение цены <code>(J(θ))</code>, тем точнее будут предсказания нашей целевой функции. 

В <strong>листинге-3</strong>, приведена простая реализация на Java функции стоимости, принимающей на вход целевую функцию, список тренировочных данных, и метки связанные с ними. Значения предсказаний будут вычисляться в цикле, и ошибка будет вычисляться вычитанием реального значения цены (взятого из метки).

Позже квадрат ошибок будет просуммирован и значение ошибки будет рассчитано. Стоимость будет возвращена как значение типа <code>double</code>:

<h4>Листинг-3</h4>
<pre class='lang-java line-numbers'><code>
public static double cost(Function&ltDouble[], Double&gt targetFunction,
 List&ltDouble[]&gt dataset,
 List&ltDouble&gt labels) {
 int m = dataset.size();
 double sumSquaredErrors = 0;

 // рассчет квадрата ошибки («разницы») для каждого тренировочного примера и //добавление его к сумме
 for (int i = 0; i < m; i++) {
 // получаем вектор признаков из текущего примера
 Double[] featureVector = dataset.get(i);
 // предсказываем значение и вычисляем ошибку базируясь на реальном
 //значении (метка)
 double predicted = targetFunction.apply(featureVector);
 double label = labels.get(i);
 double gap = predicted - label;
 sumSquaredErrors += Math.pow(gap, 2);
 }

 // Вычисляем и возращаем значение ошибки (чем меньше тем лучше)
 return (1.0 / (2 * m)) * sumSquaredErrors;
}
</code></pre>
<table>
<tr>
<td>
Интересно читать о Java? Вступайте в группу <a href='https://javarush.com/groups/java-developer' target='_blank'>Java Developer</a>!
</td>
</tr>
</table><h3>Обучение целевой функции</h3>Несмотря на то, что функция стоимости помогает оценить качество целевой функции и тета-параметров, вы все же надо найти самые подходящие параметры тета. Вы можете использовать для этого алгоритм градиентного спуска.

<h3>Градиентный спуск</h3>Градиентный спуск минимизирует функцию стоимости. Это значит, что он используется для поиска параметров тета, которые имеют минимальную стоимость <code>(J(θ))</code> на основе тренировочных данных.

Вот упрощенный алгоритм вычисления новых, более подходящих значений тета:

<div class='row justify-content-center jr-image-wrap'><div class='col-12 col-sm-10 col-md-8'><img data-id="cb3c860a-7ba8-470d-a27d-8b9b8bcf90c1" data-max-width="300" alt="Машинное обучение для Java-разработчиков, часть 2 - 5" src="https://cdn.javarush.com/images/article/cb3c860a-7ba8-470d-a27d-8b9b8bcf90c1/1024.jpeg"></div></div>
Так вот, параметры вектора тета будут улучшаться с каждой итерацией алгоритма. Коэффициент обучения α задает количество вычислений на каждой итерации. Эти вычисления можно проводить, пока не найдены «хорошие» значения тета. Для примера, функция линейной регрессии ниже имеет три параметра тета:

<div class='row justify-content-center jr-image-wrap'><div class='col-12 col-sm-10 col-md-8'><img data-id="0512fa78-728e-4402-8c53-2957f7efe15c" data-max-width="300" alt="Машинное обучение для Java-разработчиков, часть 2 - 6" src="https://cdn.javarush.com/images/article/0512fa78-728e-4402-8c53-2957f7efe15c/1024.jpeg"></div></div>
На каждой итерации будет вычислено новое значение для каждого из параметров тета: <code>θ<sub>0</sub></code>, <code>θ<sub>1<sub></code>, и <code>θ<sub>2</sub></code>. После каждой итерации, можно создать новую, более соответствующую реализацию <code >LinearRegressionFunction</code> используя новый тета вектор <span >{θ<sub>0</sub>, θ<sub>1</sub>, θ<sub>2</sub>}</span>.

В<strong> листинге-4</strong> приведен Java-код алгоритма градиентного спада. Тета для функции регрессии будут обучены с использованием тренировочных данных, данных маркеров, коэффициента обучения <code>(α)</code>. Результатом будет улучшенная целевая функция, использующая параметры тета. Метод <code >train()</code> будет вызываться снова и снова, и передавать новую целевую функцию и новые параметры тета из предыдущих вычислений. И эти вызовы будут повторяться, пока настроенная целевая функция не достигнет плато минимума:

<h4>Листинг-4</h4>
<pre class='lang-java line-numbers'><code>
public static LinearRegressionFunction train(LinearRegressionFunction targetFunction,
 List&ltDouble[]&gt dataset,
 List&ltDouble&gt labels,
 double alpha) {
 int m = dataset.size();
 double[] thetaVector = targetFunction.getThetas();
 double[] newThetaVector = new double[thetaVector.length];

 // вычисление нового значения тета для каждого элемента тета массива 
 for (int j = 0; j < thetaVector.length; j++) {
 // сумируем разницу ошибки * признак
 double sumErrors = 0;
 for (int i = 0; i < m; i++) {
 Double[] featureVector = dataset.get(i);
 double error = targetFunction.apply(featureVector) - labels.get(i);
 sumErrors += error * featureVector[j];
 }

 //вычисляем новые значения тета
 double gradient = (1.0 / m) * sumErrors;
 newThetaVector[j] = thetaVector[j] - alpha * gradient;
 }

 return new LinearRegressionFunction(newThetaVector);
}
</code></pre>
Чтобы убедиться, что стоимость постоянно уменьшается, можно запускать функцию стоимости <code>J(θ)</code> на исполнение после каждого шага обучения. После каждой итерации стоимость должна уменьшаться. Если этого не происходит, это значит, что значение коэффициента обучения слишком большое и алгоритм просто проскочил минимальное значение. В таком случае алгоритм градиентного спада терпит неудачу. 

Графики ниже демонстрируют целевую функцию, использующую новые, вычисленные, тета-параметры, начинающиеся со стартового тета-вектора <code >{1.0, 1.0}</code>. 
 
Левая колонка показывает график функции предсказания после 50 повторений; средняя колонка после 200 повторений; и правая колонка после 1000 повторений. 

Из них видно, что цена уменьшается после каждой итерации, и новая целевая функция соответствует все лучше и лучше. После 500-600 повторений тета-параметры больше существенно не меняются, и цена достигает стабильного «плато». После этого точность целевой функции улучшить таким способом не получится.

<div class='row justify-content-center jr-image-wrap'><div class='col-12 col-sm-10 col-md-8'><img data-id="6475eb9a-6a79-46ba-93e6-8b4e25a3e8fc" data-max-width="699" alt="Машинное обучение для Java-разработчиков, часть 2 - 7" src="https://cdn.javarush.com/images/article/6475eb9a-6a79-46ba-93e6-8b4e25a3e8fc/1024.jpeg"></div></div> 
В таком случае, несмотря на то, что стоимость больше значительно не уменьшается после 500-600 итераций, целевая функция все еще не оптимальна. Это свидетельствует о <strong>несоответствии</strong>. В машинном обучении термин «несоответствие» используется для обозначения того что алгоритм обучения не находит основные тенденции данных. 

Если обратиться к реальному опыту, вполне вероятно ожидать уменьшения цены за квадратный метр для бОльших владений. Отсюда мы можем сделать вывод, что модель, использованная для процесса обучения целевой функции, не соответствует данным в достаточной мере. 

Несоответствие часто связанно с чрезмерным упрощением модели. Так произошло и в нашем случае, целевая функция слишком простая, и для анализа использует единственный параметр — площадь дома. Только вот этой информации недостаточно для точного предсказания цены дома.

<h3>Добавление признаков и их масштабирование</h3>Если вы обнаружили что ваша целевая функция не соответствует проблеме, которую вы пытаетесь решить, её нужно подкорректировать. Распространенный способ корректировки несоответствия — добавление дополнительных признаков в вектор признаков.

В примере с ценой дома, можно добавить такие характеристики, как количество комнат или возраст дома. То есть вместо использования вектора с одним значением признака <code >{size}</code> для описания дома, можно использовать вектор с несколькими значениями, например, <code >{size, number-of-rooms, age}.</code>

В некоторых случаях количества признаков в доступных тренировочных данных не хватает. Тогда стоит попробовать применить полиномиальные признаки, которые вычисляются с использованием существующих. 

Например, вы имеете возможность расширить целевую функцию определения цены дома таким образом, чтобы она включала вычисляемый признак квадратных метров (x2): 

<div class='row justify-content-center jr-image-wrap'><div class='col-12 col-sm-10 col-md-8'><img data-id="95283dfb-2cd8-4e0e-88d9-778accda05f7" data-max-width="300" alt="Машинное обучение для Java-разработчиков, часть 2 - 8" src="https://cdn.javarush.com/images/article/95283dfb-2cd8-4e0e-88d9-778accda05f7/1024.jpeg"></div></div>
Использование нескольких признаков требует <strong>масштабирования признаков</strong>, которое используется для стандартизации диапазона для разных признаков. Так, диапазон значений признака <span >size<sup>2</sup></span> значительно больше диапазона значений признака size. Без масштабирования признаков, <span >size<sup>2</sup></span> будет чрезмерно влиять на функцию стоимости. Ошибка, вносимая признаком <span >size<sup>2</sup></span>, будет значительно больше ошибки, вносимой признаком size. Простой алгоритм масштабирования признаков приведен ниже:

<div class='row justify-content-center jr-image-wrap'><div class='col-12 col-sm-10 col-md-8'><img data-max-width="149" alt="Машинное обучение для Java-разработчиков, часть 2 - 9" src="https://cdn.javarush.com/images/article/1f753ea9-58d8-4d43-b5be-cfb3c980820f/original.jpeg"></div></div> 
Этот алгоритм реализован в классе <code>FeaturesScaling</code> в коде примера ниже. Класс <code >FeaturesScaling</code> представляет промышленный метод для создания функции масштабирования подстраиваемой на тренировочных данных. Внутри экземпляры тренировочных данных используются для вычисления среднего, минимального и максимального значений. 

Результирующая функция использует вектор признаков и производит новый с отмасштабированными признаками. Масштабирование признаков необходимо как для процесса обучения, так и для процесса предсказания, как показано ниже:

<pre class='lang-java line-numbers'><code>
// создание массива данных
List&ltDouble[]&gt dataset = new ArrayList&lt&gt();
dataset.add(new Double[] { 1.0, 90.0, 8100.0 }); // feature vector of house#1
dataset.add(new Double[] { 1.0, 101.0, 10201.0 }); // feature vector of house#2
dataset.add(new Double[] { 1.0, 103.0, 10609.0 }); // ...
//...

// создание меток
List&ltDouble&gt labels = new ArrayList&lt&gt();
labels.add(249.0); // price label of house#1
labels.add(338.0); // price label of house#2
labels.add(304.0); // ...
//...

// создание расширенного списка признаков
Function&ltDouble[], Double[]&gt scalingFunc = FeaturesScaling.createFunction(dataset);
List&ltDouble[]&gt scaledDataset = dataset.stream().map(scalingFunc).collect(Collectors.toList());

// создаем функцию которая инициализирует теты и осуществляет обучение //используя коэффициент обучения 0.1

LinearRegressionFunction targetFunction = new LinearRegressionFunction(new double[] { 1.0, 1.0, 1.0 });
for (int i = 0; i < 10000; i++) {
 targetFunction = Learner.train(targetFunction, scaledDataset, labels, 0.1);
}

// делаем предсказание стоимости дома с площадью 600 m2
Double[] scaledFeatureVector = scalingFunc.apply(new Double[] { 1.0, 600.0, 360000.0 });
double predictedPrice = targetFunction.apply(scaledFeatureVector);
</code></pre>
С добавлением всё большего и большего количества признаков, становится заметен рост соответствия целевой функции, однако будьте осторожны. Если вы зайдете слишком далеко и добавите слишком много признаков, вы можете в результате поучить целевую функцию, которая сверхсоответствует.

<h3>Сверхсоответствие и перекрестные проверки</h3>Сверхсоответствие возникает тогда, когда целевая функция или модель соответствует тренировочным данным слишком хорошо, настолько, что захватывает шум или случайные отклонения в тренировочных данных. Пример сверхсоответствия приведен на крайнем с права графике ниже:

<div class='row justify-content-center jr-image-wrap'><div class='col-12 col-sm-10 col-md-8'><img data-id="efd79ce0-a0b8-44b5-8bee-0ac6b4621a7f" data-max-width="700" alt="Машинное обучение для Java-разработчиков, часть 2 - 10" src="https://cdn.javarush.com/images/article/efd79ce0-a0b8-44b5-8bee-0ac6b4621a7f/1024.jpeg"></div></div> 
Как бы там ни было, сверхсоответствующая модель очень хорошо показывает себя на тренировочных данных, но при этом будет показывать плохие результаты на реальных неизвестных данных. Существует несколько путей избежать сверхсоответствия.

<ul>
<li>Использовать больший массив данных для тренировки.</li>
<li>Использовать меньше признаков как показано на графиках выше.</li>
<li>Использовать улучшенный алгоритм машинного обучения, принимающий во внимание регуляризацию.</li>
</ul>
Если алгоритм предсказания сверхсоответствует тренировочным данным, необходимо исключить признаки, которые не приносят пользы для его точности. Сложность составляет поиск признаков, которые существеннее других влияют на точность предсказания.

Как показано на графиках, сверхсоответствие можено определить визуально с помощью графиков. Это хорошо работает для графиков с 2 или 3 координатами, становится трудно построить и оценить график если вы используете больше чем 2 признака.

В перекрестной проверке вы перепроверяете модели после обучения с использованием данных не известных алгоритму после окончания процесса обучения. Доступные маркированные данные должны быть разбиты на 3 набора:

<ul>
<li>тренировочные данные;</li>
<li>проверочные данные;</li>
<li>тестовые данные.</li>
</ul>
В таком случае 60 процентов промаркированных записей, характеризующих дома, должны быть использованы в процессе обучения вариантов целевого алгоритма. После процесса обучения, половину оставшихся данных (не использованных ранее), нужно использовать для проверки того факта, что обученный целевой алгоритм работает хорошо с неизвестными данными. 

Как правило, алгоритм, который показывает лучшие результаты по сравнению с другими, и выбирается для использования. Оставшиеся данные используются для вычисления величины ошибки для окончательно выбранной модели. 

Существуют и другие техники перекрестной проверки, например, как <strong>k-fold</strong>. Однако в этой статье я не буду их описывать. 

<h3>Инструменты машинного обучения и фреймворк Weka</h3>Большинство фреймворков и библиотек предоставляют собой обширную коллекцию алгоритмов машинного обучения. Кроме этого они предоставляют удобный высокоуровневый интерфейс к обучению, проверке и обработке моделей данных. Weka один из популярнейших фреймворков для JVM.

Weka — это Java-библиотека для практического применения, которая содержит графические тесты для проверки моделей. В примере ниже библиотека Weka используется для создания набора тренировочных данных, который содержит признаки и метки. Метод <code >setClassIndex()</code> — для маркировки. В Weka метка определена как класс:

<pre class='lang-java line-numbers'><code>
// определяем атрибуты для признаков и меток
ArrayList&ltAttribute&gt attributes = new ArrayList&lt&gt();
Attribute sizeAttribute = new Attribute("sizeFeature");
attributes.add(sizeAttribute);
Attribute squaredSizeAttribute = new Attribute("squaredSizeFeature");
attributes.add(squaredSizeAttribute);
Attribute priceAttribute = new Attribute("priceLabel");
attributes.add(priceAttribute);


// создаем и заполняем список признаков 5000 примеров
Instances trainingDataset = new Instances("trainData", attributes, 5000);
trainingDataset.setClassIndex(trainingSet.numAttributes() - 1);
Instance instance = new DenseInstance(3);

instance.setValue(sizeAttribute, 90.0);
instance.setValue(squaredSizeAttribute, Math.pow(90.0, 2));
instance.setValue(priceAttribute, 249.0);
trainingDataset.add(instance);
Instance instance = new DenseInstance(3);
instance.setValue(sizeAttribute, 101.0);
...
</code></pre>
Набор данных и Образец объекта может быть сохранен и загружен из файла. Weka использует <strong>ARFF</strong> (Attribute Relation File Format) который поддерживается графическими тестами Weka. Этот набор данных используется для тренировки целевой функции, известной как классификатор в Weka.

Прежде всего вы должны определить целевую функцию. В коде ниже экземпляр классификатора <code >LinearRegression</code> будет создан. Этот классификатор будет обучен с помощью вызова <code >buildClassifier()</code>. Метод <code >buildClassifier()</code> подбирает тета параметры базируясь на тренировочных данных в поисках наилучшей целевой модели. Используя Weka, вам не придется волноваться об установке коэффициента обучения или количества итераций. Так же Weka выполняет масштабирование признаков самостоятельно.

<pre class='lang-java line-numbers'><code>
Classifier targetFunction = new LinearRegression();
targetFunction.buildClassifier(trainingDataset);
</code></pre>
После того, как выполнены эти установки, целевая функция может быть использована для предсказания цены дома, как показано ниже:

<pre class='lang-java line-numbers'><code>
Instances unlabeledInstances = new Instances("predictionset", attributes, 1);
unlabeledInstances.setClassIndex(trainingSet.numAttributes() - 1);
Instance unlabeled = new DenseInstance(3);
unlabeled.setValue(sizeAttribute, 1330.0);
unlabeled.setValue(squaredSizeAttribute, Math.pow(1330.0, 2));
unlabeledInstances.add(unlabeled);

double prediction = targetFunction.classifyInstance(unlabeledInstances.get(0));
</code></pre>
Weka предоставляет класс <code >Evaluation</code> класс для проверки обученного классификатора или модели. В коде ниже, выбранный массив проверочных данных используется, чтобы избежать ошибочных результатов. 

Результаты измерений (цена ошибки) будут выводиться на консоль. Как правило, результаты оценки используются для сравнения моделей, которые были обучены с использованием разных алгоритмов машинного обучения, или вариаций такого рода:

<pre class='lang-java line-numbers'><code>
Evaluation evaluation = new Evaluation(trainingDataset);
evaluation.evaluateModel(targetFunction, validationDataset);
System.out.println(evaluation.toSummaryString("Results", false));
</code></pre>
Пример выше использует линейную регрессию, которая предсказывает численные значения, такие, как цена дома, базируясь на входных значениях. Линейная регрессия поддерживает предсказание непрерывных числовых значений. Для предсказания бинарных значений («Да» и «Нет») нужно использовать другие алгоритмы машинного обучения. Например, дерево решений, нейронные сети или логистическую регрессию. 

<pre class='lang-java line-numbers'><code>
// использование логистической регрессии
Classifier targetFunction = new Logistic();
targetFunction.buildClassifier(trainingSet);
</code></pre>
Вы можете использовать один из этих алгоритмов, например, для предсказания того, является ли почтовое сообщение спамом, или предсказания погоды, или предсказания хорошо ли будет продаваться дом. Если вы хотите научить ваш алгоритм предсказывать погоду или на сколько быстро будет продан дом вам нужен другой набор данных, например <code >topseller:</code>

<pre class='lang-java line-numbers'><code>
// использование атрибута маркера topseller вместо атрибута маркера цена
ArrayList<String> classVal = new ArrayList<>();
classVal.add("true");
classVal.add("false");

Attribute topsellerAttribute = new Attribute("topsellerLabel", classVal);
attributes.add(topsellerAttribute);
</code></pre>

Этот набор данных будет использован для тренировки нового классификатора <code >topseller</code>. После того как он будет обучен, вызов предсказания должен возвращать индекс класса маркера, который можно использовать для получения предсказанного значения. 

<pre class='lang-java line-numbers'><code>
int idx = (int) targetFunction.classifyInstance(unlabeledInstances.get(0));
String prediction = classVal.get(idx);
</code></pre>
<big><small><h2>Заключение</h2></small></big>Хотя машинное обучение тесно связано с статистикой и использует много математических концепций, инструментарий машинного обучения позволяет начать интеграцию машинного обучения в ваши программы без глубоких знаний математики. Тем не менее, чем лучше вы поймете основополагающие алгоритмы машинного обучения такие как, например, алгоритм линейной регрессии, который мы исследовали в этой статье, тем больше будет возможностей выбрать правильный алгоритм и настроить его на оптимальную производительность.

<em><a href='https://www.javaworld.com/article/3224505/application-development/machine-learning-for-java-developers.html' target='_blank' rel="nofollow">Перевод</a> с английского. Автор — Грегор Рот (Gregor Roth), Software Architect, JavaWorld.</em> 

<table>
<tr>
<th>Что еще почитать:
</th>
</tr>
<tr>
<td>
<p><a href='https://javarush.com/groups/posts/463-5-tekhnologicheskikh-tendenciy-dlja-postroenija-uspeshnoy-karjherih-v-2018' target='_blank'>5 технологических тенденций для построения успешной карьеры в 2018</a></p>
<p><a href='https://javarush.com/groups/posts/469-mashinnoe-obuchenie-dlja-java-razrabotchikov-ch1' target='_blank'>Машинное обучение для Java-разработчиков, часть 1</a></p>
<p><a href='https://javarush.com/groups/posts/159-5-vihzovov-dlja-razvitija-iskusstvennogo-intellekta' target='_blank'>5 вызовов для развития искусственного интеллекта</a></p>
</td>
</tr>